# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m2xuZpZIkfJtl2vxmOwgyaLNGbrlR2dm

Nama : Ahmad Sholihin

Email : asholeeqeen41@gmail.com
"""

!pip install -q keras

# Impor library yang di perlukan
import keras
import numpy as np
import pandas as pd
from keras.layers import Bidirectional
from keras.layers import Dense, LSTM, Dropout
import matplotlib.pyplot as plt
import tensorflow as tf

data_train = pd.read_csv('openweatherdata-denpasar-2010-2020.csv')
data_train

# Untuk menampilkan jumlah colomns dan data
data_train.info()

data_train.isnull().sum()

date = data_train['dt_iso']
temperatur = data_train['temp']
print(temperatur.shape)
print(temperatur)

date = data_train['dt_iso'].values
temperatur = data_train['temp'].values

plt.figure(figsize=(16,5))
plt.plot(date, temperatur)
plt.title('Temperature of Denpasar City', fontsize=20);

from sklearn.model_selection import train_test_split
X_train, X_validation, y_train, y_validation = train_test_split(temperatur, date, test_size = 0.2, random_state = 42)
print("X Train= ",len(X_train))
print("X Vaidation= ",len(X_validation))
print("Y train= ",len(y_train))
print("Y Validation= ",len(y_validation))

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder = True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

tf.keras.backend.set_floatx('float64')
train_set = windowed_dataset(X_train, window_size=64, batch_size=64, shuffle_buffer=1000)
validation_set = windowed_dataset(X_validation, window_size=64, batch_size=64, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.LSTM(60),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"), 
  tf.keras.layers.Dense(1),
])

temperatur = np.array(data_train['temp'])
Mae = (data_train['temp'].max() - data_train['temp'].min()) * 0.1
print(temperatur)
print("temperature terkecil\t= ", temperatur.min())
print("temperature terbesar\t= ", temperatur.max())
print("temperature rata-rata\t= ", temperatur.mean())
print("MAE\t\t\t= ",Mae)

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,metrics=["mae"])

#Callback 10% mae
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<2.05 and logs.get('val_mae')<2.05):
      print("MAE < 10% skala data")
      self.model.stop_training = True
callbacks = myCallback()

trainmodel = model.fit(train_set,epochs=100,
                       validation_data=validation_set,verbose=2,callbacks=[callbacks])

import matplotlib.pyplot as plt

# MAE
plt.plot(trainmodel.history['mae'])
plt.plot(trainmodel.history['val_mae'])
plt.title('MAE Model and Validation Mae')
plt.ylabel('Mae')
plt.xlabel('epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()  

#Loss
plt.plot(trainmodel.history['loss'])
plt.plot(trainmodel.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()